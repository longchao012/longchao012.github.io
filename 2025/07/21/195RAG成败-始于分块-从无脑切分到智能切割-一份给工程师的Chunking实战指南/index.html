<!DOCTYPE html>
<html lang="zh-CN">
<head>
  <meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2">
<meta name="theme-color" content="#222">
<meta name="generator" content="Hexo 7.3.0">
  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png">
  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png">
  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png">
  <link rel="mask-icon" href="/images/logo.svg" color="#222">

<link rel="stylesheet" href="/css/main.css">


<link rel="stylesheet" href="/lib/font-awesome/css/font-awesome.min.css">

<script id="hexo-configurations">
    var NexT = window.NexT || {};
    var CONFIG = {"hostname":"mzfnai.com","root":"/","scheme":"Gemini","version":"7.8.0","exturl":false,"sidebar":{"position":"left","display":"post","padding":18,"offset":12,"onmobile":false},"copycode":{"enable":true,"style":"flat"},"back2top":{"enable":true,"sidebar":true,"scrollpercent":true},"bookmark":{"enable":false,"color":"#222","save":"auto"},"fancybox":false,"mediumzoom":false,"lazyload":false,"pangu":false,"comments":{"style":"tabs","active":null,"storage":true,"lazyload":false,"nav":null},"algolia":{"hits":{"per_page":10},"labels":{"input_placeholder":"搜索文章","hits_empty":"我们没有找到任何搜索结果：${query}","hits_stats":"找到${hits}个结果，耗时${time}毫秒"}},"localsearch":{"enable":true,"trigger":"auto","top_n_per_article":1,"unescape":false,"preload":false},"motion":{"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},"path":"search.xml"};
  </script>

  <meta name="description" content="深入解析RAG系统中文本分块（Chunking）的核心技术，从基础的固定长度切分到智能语义分割，提供完整的工程实践指南和优化策略，帮助工程师构建高效的RAG检索系统。">
<meta property="og:type" content="article">
<meta property="og:title" content="RAG成败，始于分块-从&quot;无脑&quot;切分到&quot;智能&quot;切割，一份给工程师的Chunking实战指南">
<meta property="og:url" content="http://mzfnai.com/2025/07/21/195RAG%E6%88%90%E8%B4%A5-%E5%A7%8B%E4%BA%8E%E5%88%86%E5%9D%97-%E4%BB%8E%E6%97%A0%E8%84%91%E5%88%87%E5%88%86%E5%88%B0%E6%99%BA%E8%83%BD%E5%88%87%E5%89%B2-%E4%B8%80%E4%BB%BD%E7%BB%99%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84Chunking%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97/index.html">
<meta property="og:site_name" content="妙知赋能AI longchao&#39;s Blog">
<meta property="og:description" content="深入解析RAG系统中文本分块（Chunking）的核心技术，从基础的固定长度切分到智能语义分割，提供完整的工程实践指南和优化策略，帮助工程师构建高效的RAG检索系统。">
<meta property="og:locale" content="zh_CN">
<meta property="article:published_time" content="2025-07-21T07:42:19.000Z">
<meta property="article:modified_time" content="2025-09-10T14:29:30.000Z">
<meta property="article:author" content="longchao">
<meta property="article:tag" content="RAG">
<meta property="article:tag" content="文档处理">
<meta property="article:tag" content="Chunking">
<meta property="article:tag" content="文本分块">
<meta property="article:tag" content="智能切割">
<meta property="article:tag" content="向量检索">
<meta name="twitter:card" content="summary">

<link rel="canonical" href="http://mzfnai.com/2025/07/21/195RAG%E6%88%90%E8%B4%A5-%E5%A7%8B%E4%BA%8E%E5%88%86%E5%9D%97-%E4%BB%8E%E6%97%A0%E8%84%91%E5%88%87%E5%88%86%E5%88%B0%E6%99%BA%E8%83%BD%E5%88%87%E5%89%B2-%E4%B8%80%E4%BB%BD%E7%BB%99%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84Chunking%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97/">


<script id="page-configurations">
  // https://hexo.io/docs/variables.html
  CONFIG.page = {
    sidebar: "",
    isHome : false,
    isPost : true,
    lang   : 'zh-CN'
  };
</script>

  <title>RAG成败，始于分块-从"无脑"切分到"智能"切割，一份给工程师的Chunking实战指南 | 妙知赋能AI longchao's Blog</title>
  






  <noscript>
  <style>
  .use-motion .brand,
  .use-motion .menu-item,
  .sidebar-inner,
  .use-motion .post-block,
  .use-motion .pagination,
  .use-motion .comments,
  .use-motion .post-header,
  .use-motion .post-body,
  .use-motion .collection-header { opacity: initial; }

  .use-motion .site-title,
  .use-motion .site-subtitle {
    opacity: initial;
    top: initial;
  }

  .use-motion .logo-line-before i { left: initial; }
  .use-motion .logo-line-after i { right: initial; }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage">
  <div class="container use-motion">
    <div class="headband"></div>

    <header class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-container">
  <div class="site-nav-toggle">
    <div class="toggle" aria-label="切换导航栏">
      <span class="toggle-line toggle-line-first"></span>
      <span class="toggle-line toggle-line-middle"></span>
      <span class="toggle-line toggle-line-last"></span>
    </div>
  </div>

  <div class="site-meta custom-logo">

    <a href="/" class="brand" rel="start">
      <span class="logo-line-before"><i></i></span>
      <h1 class="site-title">妙知赋能AI longchao's Blog</h1>
      <span class="logo-line-after"><i></i></span>
    </a>
      <p class="site-subtitle" itemprop="description">A blog about life</p>
      <a>
        <img class="custom-logo-image" src="/uploads/custom-logo.jpg" alt="妙知赋能AI longchao's Blog">
      </a>
  </div>

  <div class="site-nav-right">
    <div class="toggle popup-trigger">
        <i class="fa fa-search fa-fw fa-lg"></i>
    </div>
  </div>
</div>




<nav class="site-nav">
  <ul id="menu" class="menu">
        <li class="menu-item menu-item-home">

    <a href="/" rel="section"><i class="fa fa-fw fa-home"></i>首页</a>

  </li>
        <li class="menu-item menu-item-archives">

    <a href="/archives/" rel="section"><i class="fa fa-fw fa-archive"></i>归档</a>

  </li>
      <li class="menu-item menu-item-search">
        <a role="button" class="popup-trigger"><i class="fa fa-search fa-fw"></i>搜索
        </a>
      </li>
  </ul>
</nav>



  <div class="search-pop-overlay">
    <div class="popup search-popup">
        <div class="search-header">
  <span class="search-icon">
    <i class="fa fa-search"></i>
  </span>
  <div class="search-input-container">
    <input autocomplete="off" autocapitalize="off"
           placeholder="搜索..." spellcheck="false"
           type="search" class="search-input">
  </div>
  <span class="popup-btn-close">
    <i class="fa fa-times-circle"></i>
  </span>
</div>
<div id="search-result">
  <div id="no-result">
    <i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>
  </div>
</div>

    </div>
  </div>

</div>
    </header>

    
  <div class="reading-progress-bar"></div>


    <main class="main">
      <div class="main-inner">
        <div class="content-wrap">
          

          <div class="content post posts-expand">
            

    
  
  
  <article itemscope itemtype="http://schema.org/Article" class="post-block" lang="zh-CN">
    <link itemprop="mainEntityOfPage" href="http://mzfnai.com/2025/07/21/195RAG%E6%88%90%E8%B4%A5-%E5%A7%8B%E4%BA%8E%E5%88%86%E5%9D%97-%E4%BB%8E%E6%97%A0%E8%84%91%E5%88%87%E5%88%86%E5%88%B0%E6%99%BA%E8%83%BD%E5%88%87%E5%89%B2-%E4%B8%80%E4%BB%BD%E7%BB%99%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84Chunking%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="image" content="/images/avatar.gif">
      <meta itemprop="name" content="longchao">
      <meta itemprop="description" content="A blog about life, technology, and everything in between.">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="妙知赋能AI longchao's Blog">
    </span>
      <header class="post-header">
        <h1 class="post-title" itemprop="name headline">
          RAG成败，始于分块-从"无脑"切分到"智能"切割，一份给工程师的Chunking实战指南
        </h1>

        <div class="post-meta">
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              <span class="post-meta-item-text">发表于</span>

              <time title="创建时间：2025-07-21 15:42:19" itemprop="dateCreated datePublished" datetime="2025-07-21T15:42:19+08:00">2025-07-21</time>
            </span>
            <span class="post-meta-item">
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              <span class="post-meta-item-text">分类于</span>
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/" itemprop="url" rel="index"><span itemprop="name">AI</span></a>
                </span>
                  ，
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing">
                  <a href="/categories/AI/RAG/" itemprop="url" rel="index"><span itemprop="name">RAG</span></a>
                </span>
            </span>

          
            <span class="post-meta-item" title="阅读次数" id="busuanzi_container_page_pv" style="display: none;">
              <span class="post-meta-item-icon">
                <i class="fa fa-eye"></i>
              </span>
              <span class="post-meta-item-text">阅读次数：</span>
              <span id="busuanzi_value_page_pv"></span>
            </span>
            <div class="post-description">深入解析RAG系统中文本分块（Chunking）的核心技术，从基础的固定长度切分到智能语义分割，提供完整的工程实践指南和优化策略，帮助工程师构建高效的RAG检索系统。</div>

        </div>
      </header>

    
    
    
    <div class="post-body" itemprop="articleBody">

      
        <h2 id="导语"><a href="#导语" class="headerlink" title="导语"></a>导语</h2><p>你是否也遇到过这样的情况：RAG系统里的LLM明明很强大，Prompt也精心调校过，但最终的问答效果就是不尽如人意？答案时常上下文不全，甚至出现事实性错误。&#x20;</p>
<p>我们排查了检索算法，优化了Embedding模型，却往往忽略了数据进入向量库之前的最关键一步：文档分块。&#x20;</p>
<p>不恰当的分块，就像是给模型提供了一堆被打乱顺序、信息残缺的“坏数据”。模型能力再强，也无法从支离破碎的知识中推理出正确、完整的答案。可以说，分块的质量，直接决定了RAG系统性能的下限。</p>
<p>这篇文章，我们就来深入聊聊这个基础却至关重要的环节。本文不谈空泛的理论，而是聚焦于各类分块策略的实战代码和经验总结，希望能帮你为你的RAG系统打下最坚实的地基。</p>
<ol>
<li>分块的本质：为何与如何</li>
</ol>
<p>分块的必要性源于两个核心限制：</p>
<p>•<strong>模型上下文窗口</strong>：大语言模型（LLM）无法一次性处理无限长度的文本。分块是将长文档切分为模型可以处理的、大小适中的片段。•<strong>检索信噪比</strong>：在检索时，如果一个文本块包含过多无关信息（噪声），就会稀释核心信号，导致检索器难以精确匹配用户意图。</p>
<p>理想的分块是在上下文完整性与信息密度之间找到最佳平衡。<code>chunk_size</code>和 <code>chunk_overlap</code>是调控这一平衡的基础参数。<code>chunk_overlap</code>通过在相邻块之间保留部分重复文本，确保了跨越块边界的语义连续性。</p>
<ul>
<li>分块策略详解与代码实践</li>
</ul>
<h2 id="2-1-基础分块策略"><a href="#2-1-基础分块策略" class="headerlink" title="2.1 基础分块策略"></a>2.1 基础分块策略</h2><h3 id="2-1-1-固定长度分块"><a href="#2-1-1-固定长度分块" class="headerlink" title="2.1.1 固定长度分块"></a>2.1.1 固定长度分块</h3><p>这是最直接的方法，按预设的字符数进行切割。它不考虑文本的任何逻辑结构，实现简单，但容易破坏语义完整性。</p>
<p>•<strong>核心思想</strong>：按固定字符数 <code>chunk_size</code> 切分文本。•<strong>适用场景</strong>：结构性弱的纯文本，或对语义要求不高的预处理阶段。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from langchain_text_splitters importCharacterTextSplitter</span><br><span class="line">sample_text =(&quot;LangChain was created by Harrison Chase in 2022. It provides a framework for developing applications &quot;&quot;powered by language models. The library is known for its modularity and ease of use. &quot;&quot;One of its key components is the TextSplitter class, which helps in document chunking.&quot;)</span><br><span class="line">text_splitter =CharacterTextSplitter(    separator =&quot; &quot;,# 按空格分割    chunk_size=100,# 增大块大小    chunk_overlap=20,# 调整重叠比例    length_function=len,)</span><br><span class="line">docs = text_splitter.create_documents([sample_text])for i, doc in enumerate(docs):print(f&quot;--- Chunk &#123;i+1&#125; ---&quot;)print(doc.page_content)</span><br></pre></td></tr></table></figure>

<h3 id="2-1-2-递归字符分块"><a href="#2-1-2-递归字符分块" class="headerlink" title="2.1.2 递归字符分块"></a>2.1.2 递归字符分块</h3><p>LangChain推荐的通用策略。它按预设的字符列表（如 <code>[&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;]</code>）进行递归分割，尝试优先保留段落、句子等逻辑单元的完整性。</p>
<p>•<strong>核心思想</strong>：按层次化分隔符列表进行递归切分。•<strong>适用场景</strong>：绝大多数文本类型的首选通用策略。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from langchain_text_splitters importRecursiveCharacterTextSplitter</span><br><span class="line"># 使用与上文相同的 sample_texttext_splitter =RecursiveCharacterTextSplitter(    chunk_size=100,    chunk_overlap=20,# 默认分隔符为 [&quot;\n\n&quot;, &quot;\n&quot;, &quot; &quot;, &quot;&quot;])</span><br><span class="line">docs = text_splitter.create_documents([sample_text])for i, doc in enumerate(docs):print(f&quot;--- Chunk &#123;i+1&#125; ---&quot;)print(doc.page_content)</span><br></pre></td></tr></table></figure>

<p><strong>参数调优说明：</strong>&#x5BF9;于固定长度和递归分块，<code>chunk_size</code> 和 <code>chunk_overlap</code> 的设置至关重要：</p>
<p>•<strong><code>chunk_size</code></strong>: 决定了每个块的大小。块太小，可能导致上下文信息不足，模型无法充分理解；块太大，则可能引入过多噪声，降低检索的信噪比，并增加API调用成本。通常根据嵌入模型的最佳输入长度和文本特性来选择，例如 256, 512, 1024。•<strong><code>chunk_overlap</code></strong>: 决定了相邻块之间的重叠字符数。设置合理的重叠（如 <code>chunk_size</code> 的10%-20%）可以有效防止在块边界处切断完整的语义单元（如一个长句子），是保证语义连续性的关键。</p>
<h3 id="2-1-3-基于句子的分块"><a href="#2-1-3-基于句子的分块" class="headerlink" title="2.1.3 基于句子的分块"></a>2.1.3 基于句子的分块</h3><p>以句子为最小单元进行组合，确保了最基本的语义完整性。</p>
<p>•<strong>核心思想</strong>：将文本分割成句子，再将句子聚合成块。•<strong>适用场景</strong>：对句子完整性要求高的场景，如法律文书、新闻报道。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">import nltktry:    nltk.data.find(&#x27;tokenizers/punkt&#x27;)except nltk.downloader.DownloadError:    nltk.download(&#x27;punkt&#x27;)</span><br><span class="line">from nltk.tokenize import sent_tokenize</span><br><span class="line">def chunk_by_sentences(text, max_chars=500, overlap_sentences=1):    sentences = sent_tokenize(text)    chunks =[]    current_chunk =&quot;&quot;for i, sentence in enumerate(sentences):if len(current_chunk)+ len(sentence)&lt;= max_chars:            current_chunk +=&quot; &quot;+ sentenceelse:            chunks.append(current_chunk.strip())# 创建重叠            start_index = max(0, i - overlap_sentences)            current_chunk =&quot; &quot;.join(sentences[start_index:i+1])if current_chunk:        chunks.append(current_chunk.strip())return chunks</span><br><span class="line">long_text =&quot;This is the first sentence. This is the second sentence, which is a bit longer. Now we have a third one. The fourth sentence follows. Finally, the fifth sentence concludes this paragraph.&quot;chunks = chunk_by_sentences(long_text, max_chars=100)for i, chunk in enumerate(chunks):print(f&quot;--- Chunk &#123;i+1&#125; ---&quot;)print(chunk)</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：语言模型的选择</strong>许多标准库的默认配置是为英文设计的。例如，<code>nltk.tokenize.sent_tokenize</code> 默认使用基于英文训练的Punkt模型进行分句。如果直接用于处理中文文本，会因无法识别中文标点而导致分句失败。 处理中文时，必须采用适合中文的分割方法，例如：</p>
<p>•基于中文标点符号（如 。！？）的正则表达式进行切分。•使用加载了中文模型的NLP库（如 spaCy, HanLP 等）进行更准确的分句。</p>
<h2 id="2-2-结构感知分块"><a href="#2-2-结构感知分块" class="headerlink" title="2.2 结构感知分块"></a>2.2 结构感知分块</h2><p>利用文档固有的结构信息（如标题、列表、对话轮次）作为分块边界，这种方法逻辑性强，能更好地保留上下文。</p>
<h3 id="2-2-1-结构化文本分块"><a href="#2-2-1-结构化文本分块" class="headerlink" title="2.2.1 结构化文本分块"></a>2.2.1 结构化文本分块</h3><p>•<strong>核心思想</strong>：根据Markdown的标题层级或HTML的标签来定义块的边界。•<strong>适用场景</strong>：格式规范的Markdown、HTML文档。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">from langchain_text_splitters importMarkdownHeaderTextSplitter</span><br><span class="line">markdown_document =&quot;&quot;&quot;# Chapter 1: The Beginning</span><br><span class="line">## Section 1.1: The Old WorldThisis the story of a time long past.</span><br><span class="line">## Section 1.2: A New HopeA new hero emerges.</span><br><span class="line"># Chapter 2: The Journey</span><br><span class="line">## Section 2.1: The Call to AdventureThe hero receives a mysterious call.&quot;&quot;&quot;</span><br><span class="line">headers_to_split_on =[(&quot;#&quot;,&quot;Header 1&quot;),(&quot;##&quot;,&quot;Header 2&quot;),]</span><br><span class="line">markdown_splitter =MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)md_header_splits = markdown_splitter.split_text(markdown_document)</span><br><span class="line">for split in md_header_splits:print(f&quot;Metadata: &#123;split.metadata&#125;&quot;)print(split.page_content)print(&quot;-&quot;*20)</span><br></pre></td></tr></table></figure>

<h3 id="2-2-2-对话式分块"><a href="#2-2-2-对话式分块" class="headerlink" title="2.2.2 对话式分块"></a>2.2.2 对话式分块</h3><p>•<strong>核心思想</strong>：根据对话的发言人或轮次进行分块。•<strong>适用场景</strong>：客服对话、访谈记录、会议纪要。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dialogue =[&quot;Alice: Hi, I&#x27;m having trouble with my order.&quot;,&quot;Bot: I can help with that. What&#x27;s your order number?&quot;,&quot;Alice: It&#x27;s 12345.&quot;,&quot;Alice: I haven&#x27;t received any shipping updates.&quot;,&quot;Bot: Let me check... It seems your order was shipped yesterday.&quot;,&quot;Alice: Oh, great! Thank you.&quot;,]</span><br><span class="line">def chunk_dialogue(dialogue_lines, max_turns_per_chunk=3):    chunks =[]for i in range(0, len(dialogue_lines), max_turns_per_chunk):        chunk =&quot;\n&quot;.join(dialogue_lines[i:i + max_turns_per_chunk])        chunks.append(chunk)return chunks</span><br><span class="line">chunks = chunk_dialogue(dialogue)for i, chunk in enumerate(chunks):print(f&quot;--- Chunk &#123;i+1&#125; ---&quot;)print(chunk)</span><br></pre></td></tr></table></figure>

<h2 id="2-3-语义与主题分块"><a href="#2-3-语义与主题分块" class="headerlink" title="2.3 语义与主题分块"></a>2.3 语义与主题分块</h2><p>这类方法超越了文本的物理结构，根据内容的语义含义进行切分。</p>
<h3 id="2-3-1-语义分块"><a href="#2-3-1-语义分块" class="headerlink" title="2.3.1 语义分块"></a>2.3.1 语义分块</h3><p>•<strong>核心思想</strong>：计算相邻句子&#x2F;段落的向量相似度，在语义发生突变（相似度低）的位置进行切分。•<strong>适用场景</strong>：知识库、研究论文等需要高精度语义内聚的文档。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">import osfrom langchain_experimental.text_splitter importSemanticChunkerfrom langchain_huggingface importHuggingFaceEmbeddings</span><br><span class="line">os.environ[&quot;TOKENIZERS_PARALLELISM&quot;]=&quot;false&quot;embeddings =HuggingFaceEmbeddings(model_name=&quot;sentence-transformers/all-MiniLM-L6-v2&quot;)</span><br><span class="line"># 创建 SemanticChunker 实例# LangChain 的 SemanticChunker 默认使用 percentile 阈值# 可以尝试不同的 breakpoint_threshold_type: &quot;percentile&quot;, &quot;standard_deviation&quot;, &quot;interquartile&quot;, &quot;gradient&quot;text_splitter =SemanticChunker(    embeddings,    breakpoint_threshold_type=&quot;percentile&quot;,# 使用百分位作为阈值类型    breakpoint_threshold_amount=70# 设置阈值为80)print(&quot;SemanticChunker configured.&quot;)print(&quot;-&quot;*50)</span><br><span class="line">long_text =(&quot;The Wright brothers, Orville and Wilbur, were two American aviation pioneers &quot;&quot;generally credited with inventing, building, and flying the world&#x27;s first successful motor-operated airplane. &quot;&quot;They made the first controlled, sustained flight of a powered, heavier-than-air aircraft on December 17, 1903. &quot;&quot;In the following years, they continued to develop their aircraft. &quot;&quot;Switching topics completely, let&#x27;s talk about cooking. &quot;&quot;A good pizza starts with a perfect dough, which needs yeast, flour, water, and salt. &quot;&quot;The sauce is typically tomato-based, seasoned with herbs like oregano and basil. &quot;&quot;Toppings can vary from simple mozzarella to a wide range of meats and vegetables. &quot;&quot;Finally, let&#x27;s consider the solar system. &quot;&quot;It is a gravitationally bound system of the Sun and the objects that orbit it. &quot;&quot;The largest objects are the eight planets, in order from the Sun: Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, and Neptune.&quot;)</span><br><span class="line">docs = text_splitter.create_documents([long_text])</span><br><span class="line">for i, doc in enumerate(docs):print(f&quot;--- Chunk &#123;i+1&#125; ---&quot;)print(doc.page_content)print()</span><br></pre></td></tr></table></figure>

<p><strong>参数调优说明：</strong><code>SemanticChunker</code> 的效果高度依赖 <code>breakpoint_threshold_amount</code> 这个阈值参数。</p>
<p>•<strong>阈值的作用</strong>：可以将其理解为一个“语义变化敏感度”的控制器。当相邻句子的语义相似度差异超过这个阈值时，就在此处进行切分。•<strong>如何调整</strong>：<strong>阈值较低</strong>：切分会非常敏感，即使微小的语义变化也可能导致分块。这会产生大量非常小且高度内聚的块。<strong>阈值较高</strong>：对语义变化的容忍度更大，只有在话题发生显著转变时才会切分，从而产生更少、更大的块。•这个值没有固定的最佳答案，需要根据您的文档内容和领域进行反复实验和调整，以达到最理想的分块效果。</p>
<h3 id="2-3-2-基于主题的分块"><a href="#2-3-2-基于主题的分块" class="headerlink" title="2.3.2 基于主题的分块"></a>2.3.2 基于主题的分块</h3><p>•<strong>核心思想</strong>：利用主题模型（如LDA）或聚类算法，在文档的宏观主题发生转换时进行切分。•<strong>适用场景</strong>：长篇、多主题的报告或书籍。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import numpy as npimport refrom sklearn.feature_extraction.text importCountVectorizerfrom sklearn.decomposition importLatentDirichletAllocationimport nltkfrom nltk.corpus import stopwords</span><br><span class="line">try:    stopwords.words(&#x27;english&#x27;)exceptLookupError:    nltk.download(&#x27;stopwords&#x27;)</span><br><span class="line">def lda_topic_chunking(text: str, n_topics:int=3)-&gt; list[str]:&quot;&quot;&quot;基于LDA主题模型的分块函数。</span><br><span class="line">:param text:需要分块的原始文本。:param n_topics:期望从文本中发现的主题数量。:return:文本块列表。&quot;&quot;&quot;# 1. 文本预处理 和 重新定义“文档”单元# 将文本按段落分割，一个段落作为一个“文档”    paragraphs =[p.strip()for p in text.split(&#x27;\n\n&#x27;)if p.strip()]if len(paragraphs)&lt;=1:return[text]# 如果只有一个段落，无需分割</span><br><span class="line"># 简单的文本清洗：移除特殊字符，转为小写    cleaned_paragraphs =[re.sub(r&#x27;[^a-zA-Z\s]&#x27;,&#x27;&#x27;, p).lower()for p in paragraphs]</span><br><span class="line"># 2. 词袋模型 + 去停用词# min_df=1 因为在单文档上下文中，一个词只在一个段落出现也是有意义的    vectorizer =CountVectorizer(min_df=1, stop_words=stopwords.words(&#x27;english&#x27;))    X = vectorizer.fit_transform(cleaned_paragraphs)</span><br><span class="line"># 如果词汇表为空，则无法进行LDA，直接返回段落if X.shape[1]==0:return paragraphs</span><br><span class="line"># 3. LDA 主题建模# n_components 是正确的参数名    lda =LatentDirichletAllocation(n_components=n_topics, random_state=42)    lda.fit(X)</span><br><span class="line"># 4. 计算每个段落的主导主题    topic_dist = lda.transform(X)# np.argmax 返回每行（每个段落）最大值的索引（即主导主题的编号）    dominant_topics = np.argmax(topic_dist, axis=1)</span><br><span class="line"># 5. 实现正确的分块逻辑：在主题变化时切分    chunks =[]    current_chunk_paragraphs =[]# 第一个段落的主题作为起始主题    current_topic = dominant_topics[0]</span><br><span class="line">for i, paragraph in enumerate(paragraphs):if dominant_topics[i]== current_topic:# 如果主题相同，则加入当前块            current_chunk_paragraphs.append(paragraph)else:# 如果主题变化，则保存上一个块，并开始一个新块            chunks.append(&quot;\n\n&quot;.join(current_chunk_paragraphs))            current_chunk_paragraphs =[paragraph]            current_topic = dominant_topics[i]</span><br><span class="line"># 添加最后一个块    chunks.append(&quot;\n\n&quot;.join(current_chunk_paragraphs))</span><br><span class="line">return chunks</span><br><span class="line">document =&quot;&quot;&quot;...............................&quot;&quot;&quot;</span><br><span class="line">final_chunks = lda_topic_chunking(document, n_topics=3)</span><br><span class="line">print(f&quot;文档被分成了 &#123;len(final_chunks)&#125; 个块：&quot;)print(&quot;=&quot;*80)for i, chunk in enumerate(final_chunks):print(f&quot;--- 块 &#123;i+1&#125; ---&quot;)print(chunk)print(&quot;-&quot;*80)</span><br></pre></td></tr></table></figure>

<p><strong>注意事项：</strong>&#x57FA;于主题的分块在实践中需要谨慎使用，因为它存在一些固有挑战：</p>
<p>•<strong>数据依赖性强</strong>：主题模型和聚类算法通常需要足够长的文本和明确的主题区分度才能生效。对于短文本或主题交叉频繁的文档，效果可能不佳。•<strong>预处理要求高</strong>：文本清洗、停用词去除、词形还原等预处理步骤对最终的主题识别质量有巨大影响。•<strong>超参数敏感</strong>：需要预先设定主题数量（<code>n_topics</code>）等超参数，而这往往难以准确估计。</p>
<p>因此，当直接应用此类方法时，可能会发现分出的块在逻辑上不连贯，或者与实际主题边界不符。 此方法更适合作为一种探索性工具，在主题边界清晰的长文档上使用，并需要进行充分的实验验证。</p>
<h2 id="2-4-高级分块策略"><a href="#2-4-高级分块策略" class="headerlink" title="2.4 高级分块策略"></a>2.4 高级分块策略</h2><h3 id="2-4-1-小-大分块"><a href="#2-4-1-小-大分块" class="headerlink" title="2.4.1 小-大分块"></a>2.4.1 小-大分块</h3><p>•<strong>核心思想</strong>：使用小块（如句子）进行高精度检索，然后将包含该小块的原始大块（如段落）作为上下文送入LLM。•<strong>适用场景</strong>：需要高检索精度和丰富生成上下文的复杂问答场景。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from langchain.embeddings importOpenAIEmbeddingsfrom langchain_text_splitters importRecursiveCharacterTextSplitterfrom langchain.retrievers importParentDocumentRetrieverfrom langchain_community.document_loaders importTextLoaderfrom langchain_chroma importChromafrom langchain.storage importInMemoryStore# from langchain_core.documents import Document # 假设 Document 已被导入</span><br><span class="line"># docs = [Document(page_content=&quot;......&quot;)] # 假设这是你的文档# embeddings = OpenAIEmbeddings()# vectorstore = Chroma(embedding_function=embeddings, collection_name=&quot;split_parents&quot;)# store = InMemoryStore()</span><br><span class="line"># parent_splitter = RecursiveCharacterTextSplitter(chunk_size=2000)# child_splitter = RecursiveCharacterTextSplitter(chunk_size=400)</span><br><span class="line"># retriever = ParentDocumentRetriever(#     vectorstore=vectorstore,#     docstore=store,#     child_splitter=child_splitter,#     parent_splitter=parent_splitter,# )</span><br><span class="line"># retriever.add_documents(docs)# sub_docs = vectorstore.similarity_search(&quot;query&quot;)# retrieved_docs = retriever.get_relevant_documents(&quot;query&quot;)# print(retrieved_docs[0].page_content)</span><br></pre></td></tr></table></figure>

<h3 id="2-4-2-代理式分块"><a href="#2-4-2-代理式分块" class="headerlink" title="2.4.2 代理式分块"></a>2.4.2 代理式分块</h3><p>•<strong>核心思想</strong>：利用一个LLM Agent来模拟人类的阅读理解过程，动态决定分块边界。•<strong>适用场景</strong>：实验性项目，或处理高度复杂、非结构化的文本。</p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><span class="line">import textwrapfrom langchain_openai importChatOpenAIfrom langchain.prompts importPromptTemplatefrom langchain_core.output_parsers importPydanticOutputParserfrom pydantic importBaseModel,Fieldfrom typing importList</span><br><span class="line">classKnowledgeChunk(BaseModel):    chunk_title: str =Field(description=&quot;这个知识块的简洁明了的标题&quot;)    chunk_text: str =Field(description=&quot;从原文中提取并重组的、自包含的文本内容&quot;)    representative_question: str =Field(description=&quot;一个可以被这个块内容直接回答的典型问题&quot;)</span><br><span class="line">classChunkList(BaseModel):    chunks:List[KnowledgeChunk]</span><br><span class="line">parser =PydanticOutputParser(pydantic_object=ChunkList)</span><br><span class="line">prompt_template =&quot;&quot;&quot;【角色】:你是一位顶尖的科学文档分析师，你的任务是将复杂的科学文本段落，分解成一组核心的、自包含的“知识块(KnowledgeChunks)”。【核心任务】:阅读用户提供的文本段落，识别其中包含的独立的核心概念。【规则】:1.**自包含性**:每个“知识块”必须是“自包含的(self-contained)”。2.**概念单一性**:每个“知识块”应该只围绕一个核心概念。3.**提取并重组**:从原文中提取与该核心概念相关的所有句子，并将它们组合成一个通顺、连贯的段落。4.**遵循格式**:严格按照下面的JSON格式指令来构建你的输出。</span><br><span class="line">&#123;format_instructions&#125;</span><br><span class="line">【待处理文本】:&#123;paragraph_text&#125;&quot;&quot;&quot;prompt =PromptTemplate(template=prompt_template,    input_variables=[&quot;paragraph_text&quot;],    partial_variables=&#123;&quot;format_instructions&quot;: parser.get_format_instructions()&#125;,)</span><br><span class="line"># 以下 model 定义需要根据实际情况修改# model = ChatOpenAI(model=&quot;Qwen3-235B-A22B&quot;, base_url=&quot;http://10.1.18.99:8089/v1&quot;,api_key=&quot;sk-&quot;,temperature=0.0).bind(#     response_format=&#123;&quot;type&quot;: &quot;json_object&quot;&#125;# )# chain = prompt | model | parser</span><br><span class="line">def agentic_chunker(paragraph_text: str)-&gt;List[KnowledgeChunk]:try:# result: ChunkList = chain.invoke(&#123;&quot;paragraph_text&quot;: paragraph_text&#125;)# return result.chunks# 模拟返回，因为无法执行 chain.invokeprint(&quot;模拟 agentic_chunker 调用&quot;)return[]exceptExceptionas e:return[]</span><br><span class="line">document =&quot;&quot;&quot;水循环，也称为水文循环，描述了水在地球表面、之上和之下的连续运动。这个循环至关重要，因为它确保了水对所有生命形式的可用性。循环的第一阶段是蒸发，这是水从海洋、湖泊和河流等表面转化为水蒸气并上升到大气中的过程，植物的蒸腾作用也对此有贡献。当温暖、潮湿的空气上升并冷却时，会发生第二阶段：凝结。在这个阶段，水蒸气变回微小的液态水滴，形成云。随着这些水滴碰撞并增长，它们最终变得足够重，以降水的形式落回地球，这是第三阶段，形式可以是雨、雪、雨夹雪或冰雹。最后，一旦水到达地面，它可能以多种方式移动，构成了第四个阶段：汇集。一些水会作为地表径流流入河流、湖泊和海洋。其他水则会渗入地下，成为地下水，最终也可能返回地表或海洋，从而重新开始整个循环。&quot;&quot;&quot;paragraphs = document.strip().split(&#x27;\n\n&#x27;)all_chunks =[]</span><br><span class="line">for i, para in enumerate(paragraphs):print(f&quot;--- 正在处理第 &#123;i+1&#125;/&#123;len(paragraphs)&#125; 段 ---&quot;)    chunks_from_para = agentic_chunker(para)# 调用新函数if chunks_from_para:        all_chunks.extend(chunks_from_para)print(f&quot;成功从该段落中提取了 &#123;len(chunks_from_para)&#125; 个知识块。&quot;)</span><br><span class="line">ifnot all_chunks:print(&quot;未能生成任何知识块。&quot;)else:for i, chunk in enumerate(all_chunks):print(f&quot;【知识块 &#123;i+1&#125;】&quot;)print(f&quot;  - 标题: &#123;chunk.chunk_title&#125;&quot;)print(f&quot;  - 代表性问题: &#123;chunk.representative_question&#125;&quot;)print(f&quot;  - 文本内容:&quot;)        wrapped_text = textwrap.fill(chunk.chunk_text, width=78, initial_indent=&#x27;    &#x27;, subsequent_indent=&#x27;    &#x27;)print(wrapped_text)print(&quot;-&quot;*80)</span><br></pre></td></tr></table></figure>

<ul>
<li>混合分块：平衡效率与质量</li>
</ul>
<p>在实践中，单一策略往往难以应对所有情况。混合分块结合了多种策略的优点，是一种非常实用的技巧。</p>
<p>•<strong>核心思想</strong>：先用一种宏观策略（如结构化分块）进行粗粒度切分，再对过大的块使用更精细的策略（如递归或语义分块）进行二次切分。•<strong>适用场景</strong>：处理结构复杂且内容密度不均的文档。</p>
<p><strong>代码示例 (结构化 + 递归混合):</strong></p>
<figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><span class="line"></span><br><span class="line">from langchain_text_splitters importMarkdownHeaderTextSplitter,RecursiveCharacterTextSplitterfrom langchain_core.documents importDocument</span><br><span class="line">markdown_document =&quot;&quot;&quot;# 第一章：公司简介</span><br><span class="line">本公司成立于2017年，致力于推动人工智能技术的创新与应用。我们的使命是通过先进的AI解决方案，为各行各业赋能，创造更大的价值。我们拥有一支由顶尖科学家和工程师组成的团队，专注于深度学习、自然语言处理和计算机视觉等前沿领域。</span><br><span class="line">## 1.1 发展历程</span><br><span class="line">公司自创立以来，经历了快速的发展。从最初的几人团队，到如今拥有数百名员工的规模，我们始终坚持技术驱动、客户至上的原则。</span><br><span class="line"># 第二章：核心技术</span><br><span class="line">本章将详细介绍我们的核心技术。我们的技术框架基于先进的分布式计算理念，确保了高可用性和可扩展性。系统的核心是一个自主研发的深度学习引擎，它能够处理海量数据并进行高效的模型训练。这个引擎支持多种神经网络结构，包括卷积神经网络（CNNs）用于图像识别，以及循环神经网络（RNNs）和Transformer模型用于自然语言理解。我们特别优化了Transformer架构，提出了一种名为“注意力压缩”的新机制，该机制在保持模型性能的同时，显著减少了计算资源的需求。这一创新使得我们能够在边缘设备上部署复杂的AI模型，为物联网（IoT）应用场景提供了强大的支持。不仅如此，我们还构建了一套完整的数据处理流水线，从数据采集、清洗、标注到最终的模型评估，全程自动化，极大地提升了研发效率。这套流水线处理的数据量已达到PB级别，每日处理的请求数超过十亿次。为了保障数据安全，我们采用了端到-端加密和联邦学习等多种先进技术，确保客户数据的隐私和安全。我们相信，强大的技术实力是公司发展的基石，也是我们服务客户的信心所在。我们不断探索技术的边界，致力于将最新的科研成果转化为可靠、易用的产品和服务，帮助客户在激烈的市场竞争中保持领先地位。</span><br><span class="line">## 2.1 技术原理</span><br><span class="line">我们的技术原理融合了统计学、机器学习和运筹学等多个学科的知识。</span><br><span class="line"># 第三章：未来展望</span><br><span class="line">展望未来，我们将继续加大在人工智能领域的投入，探索通用人工智能（AGI）的可能性。</span><br><span class="line">&quot;&quot;&quot;</span><br><span class="line"># 定义混合分块函数def hybrid_chunking_optimized(    markdown_document: str,    coarse_chunk_threshold:int=400,# 定义一个粗粒度块的大小阈值    fine_chunk_size:int=100,# 定义精细切分的目标大小    fine_chunk_overlap:int=20# 定义精细切分的重叠大小)-&gt; list[Document]:&quot;&quot;&quot;使用结构化+递归的混合策略，并确保元数据在二次切分中得以保留。</span><br><span class="line">:param markdown_document:完整的Markdown格式文档。:param coarse_chunk_threshold:粗粒度块的长度阈值，超过则进行二次切分。:param fine_chunk_size:二次切分时，每个小块的目标长度。:param fine_chunk_overlap:二次切分时，小块间的重叠长度。:return:Document对象的列表，包含最终的所有分块。&quot;&quot;&quot;# 宏观的结构化分块 (按H1和H2标题)    headers_to_split_on =[(&quot;#&quot;,&quot;Header 1&quot;),(&quot;##&quot;,&quot;Header 2&quot;)]    markdown_splitter =MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)    coarse_chunks = markdown_splitter.split_text(markdown_document)</span><br><span class="line"># 初始化精细分块器    fine_splitter =RecursiveCharacterTextSplitter(        chunk_size=fine_chunk_size,        chunk_overlap=fine_chunk_overlap)</span><br><span class="line"># 迭代处理，对过大的块进行二次切分    final_chunks =[]for chunk in coarse_chunks:# 检查块的文本长度是否超过阈值if len(chunk.page_content)&gt; coarse_chunk_threshold:print(f&quot;--- 块过大 (长度: &#123;len(chunk.page_content)&#125;), 正在进行二次切分... ---&quot;)print(f&quot;    原始元数据: &#123;chunk.metadata&#125;&quot;)</span><br><span class="line">            finer_chunks = fine_splitter.split_documents([chunk])            final_chunks.extend(finer_chunks)else:            final_chunks.append(chunk)</span><br><span class="line">return final_chunks</span><br><span class="line">final_chunks = hybrid_chunking_optimized(markdown_document)</span><br><span class="line">for i, chunk in enumerate(final_chunks):print(f&quot;--- 最终块 &#123;i+1&#125; (长度: &#123;len(chunk.page_content)&#125;) ---&quot;)print(f&quot;元数据: &#123;chunk.metadata&#125;&quot;)print(&quot;文本内容:&quot;)print(chunk.page_content)print(&quot;-&quot;*80)</span><br></pre></td></tr></table></figure>

<ul>
<li>如何选择最佳分块策略？</li>
</ul>
<p>面对众多策略，合理的选择路径比逐一尝试更重要。个人建议遵循以下分层决策框架，从简单高效的基准开始，逐步引入更复杂的策略。</p>
<p><strong>第一步：从基准策略开始</strong></p>
<p>•<strong>默认选项</strong>：<code>RecursiveCharacterTextSplitter</code> 无论处理何种文本，这都是最稳妥的起点。它在通用性、简单性和效果之间取得了很好的平衡。首先使用它建立一个性能基线。</p>
<p><strong>第二步：检查结构化特征</strong></p>
<p>•<strong>优先选项</strong>：结构感知分块 在应用基准策略后，检查你的文档是否具有明确的结构，如Markdown标题、HTML标签、代码或对话格式。如果有，可以切换到 <code>MarkdownHeaderTextSplitter</code>等相应的结构化分块方法。这是成本最低、收益较好的优化步骤。</p>
<p><strong>第三步：当精度成为瓶颈时</strong></p>
<p>•<strong>进阶选项</strong>：语义分块 或 小-大分块 如果基础策略和结构化策略的检索效果仍不理想，无法满足业务需求，说明需要更高维度的语义信息。•<strong><code>SemanticChunker</code></strong>：适用于需要块内语义高度一致的场景。•<strong><code>ParentDocumentRetriever</code> (小-大分块)</strong>：适用于既要保证检索精准度，又需要为LLM提供完整上下文的复杂问答场景。</p>
<p><strong>第四步：应对极端复杂的文档</strong></p>
<p>•<strong>高级实践</strong>：混合分块 对于那些结构复杂、内容密度不均、混合多种格式的复杂文档，单一策略难以应对。此时，混合分块是平衡成本与效果的最佳实践。例如，先用 <code>MarkdownHeaderTextSplitter</code>进行宏观切分，再对过长的块用 <code>RecursiveCharacterTextSplitter</code>进行二次细分。</p>
<p>为了方便查阅和对比，下表总结了所有讨论过的分块策略。</p>
<h1 id="结论：分块是实践，而非理论"><a href="#结论：分块是实践，而非理论" class="headerlink" title="结论：分块是实践，而非理论"></a>结论：分块是实践，而非理论</h1><p>文档分块，远不止是简单的文本预处理，它深刻影响着RAG系统中信息流的质量，是典型的“细节决定成败”的环节。 通过本文的梳理，我们应形成三个核心认知：</p>
<p>1.<strong>不存在“银弹”</strong>：没有任何一种分块策略能完美适应所有场景。将分块视为一个需要根据数据特性和业务需求不断迭代优化的工程问题。2.<strong>始于简单，终于复合</strong>：始终从 <code>RecursiveCharacterTextSplitter</code>等简单、可靠的方法入手建立基线，再根据需要逐步引入结构化、语义化乃至混合策略，是一种高效且稳健的实践路径。3.<strong>分块即“建模”</strong>：从某种意义上说，如何分块，就是你如何理解和“建模”你的知识。一个高质量的分块，本身就是对原始数据的一种结构化和语义增强。</p>
<p>最终，高质量的分块是通往高质量生成结果的前提。掌握这项技能，是每一位RAG应用构建者提升系统性能的必经之路。</p>

    </div>

    
    
    
        

<div>
<ul class="post-copyright">
  <li class="post-copyright-author">
    <strong>本文作者： </strong>longchao
  </li>
  <li class="post-copyright-link">
    <strong>本文链接：</strong>
    <a href="http://mzfnai.com/2025/07/21/195RAG%E6%88%90%E8%B4%A5-%E5%A7%8B%E4%BA%8E%E5%88%86%E5%9D%97-%E4%BB%8E%E6%97%A0%E8%84%91%E5%88%87%E5%88%86%E5%88%B0%E6%99%BA%E8%83%BD%E5%88%87%E5%89%B2-%E4%B8%80%E4%BB%BD%E7%BB%99%E5%B7%A5%E7%A8%8B%E5%B8%88%E7%9A%84Chunking%E5%AE%9E%E6%88%98%E6%8C%87%E5%8D%97/" title="RAG成败，始于分块-从&quot;无脑&quot;切分到&quot;智能&quot;切割，一份给工程师的Chunking实战指南">http://mzfnai.com/2025/07/21/195RAG成败-始于分块-从无脑切分到智能切割-一份给工程师的Chunking实战指南/</a>
  </li>
  <li class="post-copyright-license">
    <strong>版权声明： </strong>本博客所有文章除特别声明外，均采用 <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" rel="noopener" target="_blank"><i class="fa fa-fw fa-creative-commons"></i>BY-NC-SA</a> 许可协议。转载请注明出处！
  </li>
</ul>
</div>


      <footer class="post-footer">
          <div class="post-tags">
              <a href="/tags/RAG/" rel="tag"># RAG</a>
              <a href="/tags/%E6%96%87%E6%A1%A3%E5%A4%84%E7%90%86/" rel="tag"># 文档处理</a>
              <a href="/tags/Chunking/" rel="tag"># Chunking</a>
              <a href="/tags/%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97/" rel="tag"># 文本分块</a>
              <a href="/tags/%E6%99%BA%E8%83%BD%E5%88%87%E5%89%B2/" rel="tag"># 智能切割</a>
              <a href="/tags/%E5%90%91%E9%87%8F%E6%A3%80%E7%B4%A2/" rel="tag"># 向量检索</a>
          </div>

        


        
    <div class="post-nav">
      <div class="post-nav-item">
    <a href="/2025/07/20/194RAG%E7%AF%87-%E9%A1%B9%E7%9B%AE%E4%BC%98%E5%8C%96%E6%9C%80%E4%BD%B3%E5%AE%9E%E8%B7%B5/" rel="prev" title="RAG篇-项目优化最佳实践">
      <i class="fa fa-chevron-left"></i> RAG篇-项目优化最佳实践
    </a></div>
      <div class="post-nav-item">
    <a href="/2025/07/22/196Agent%E7%AF%87-agent%E5%BF%AB%E9%80%9F%E5%85%A5%E9%97%A8/" rel="next" title="Agent篇-agent快速入门">
      Agent篇-agent快速入门 <i class="fa fa-chevron-right"></i>
    </a></div>
    </div>
      </footer>
    
  </article>
  
  
  



          </div>
          

<script>
  window.addEventListener('tabs:register', () => {
    let { activeClass } = CONFIG.comments;
    if (CONFIG.comments.storage) {
      activeClass = localStorage.getItem('comments_active') || activeClass;
    }
    if (activeClass) {
      let activeTab = document.querySelector(`a[href="#comment-${activeClass}"]`);
      if (activeTab) {
        activeTab.click();
      }
    }
  });
  if (CONFIG.comments.storage) {
    window.addEventListener('tabs:click', event => {
      if (!event.target.matches('.tabs-comment .tab-content .tab-pane')) return;
      let commentClass = event.target.classList[1];
      localStorage.setItem('comments_active', commentClass);
    });
  }
</script>

        </div>
          
  
  <div class="toggle sidebar-toggle">
    <span class="toggle-line toggle-line-first"></span>
    <span class="toggle-line toggle-line-middle"></span>
    <span class="toggle-line toggle-line-last"></span>
  </div>

  <aside class="sidebar">
    <div class="sidebar-inner">

      <ul class="sidebar-nav motion-element">
        <li class="sidebar-nav-toc">
          文章目录
        </li>
        <li class="sidebar-nav-overview">
          站点概览
        </li>
      </ul>

      <!--noindex-->
      <div class="post-toc-wrap sidebar-panel">
          <div class="post-toc motion-element"><ol class="nav"><li class="nav-item nav-level-2"><a class="nav-link" href="#%E5%AF%BC%E8%AF%AD"><span class="nav-number">1.</span> <span class="nav-text">导语</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-1-%E5%9F%BA%E7%A1%80%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5"><span class="nav-number">2.</span> <span class="nav-text">2.1 基础分块策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-1-%E5%9B%BA%E5%AE%9A%E9%95%BF%E5%BA%A6%E5%88%86%E5%9D%97"><span class="nav-number">2.1.</span> <span class="nav-text">2.1.1 固定长度分块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-2-%E9%80%92%E5%BD%92%E5%AD%97%E7%AC%A6%E5%88%86%E5%9D%97"><span class="nav-number">2.2.</span> <span class="nav-text">2.1.2 递归字符分块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-1-3-%E5%9F%BA%E4%BA%8E%E5%8F%A5%E5%AD%90%E7%9A%84%E5%88%86%E5%9D%97"><span class="nav-number">2.3.</span> <span class="nav-text">2.1.3 基于句子的分块</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-2-%E7%BB%93%E6%9E%84%E6%84%9F%E7%9F%A5%E5%88%86%E5%9D%97"><span class="nav-number">3.</span> <span class="nav-text">2.2 结构感知分块</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-1-%E7%BB%93%E6%9E%84%E5%8C%96%E6%96%87%E6%9C%AC%E5%88%86%E5%9D%97"><span class="nav-number">3.1.</span> <span class="nav-text">2.2.1 结构化文本分块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-2-2-%E5%AF%B9%E8%AF%9D%E5%BC%8F%E5%88%86%E5%9D%97"><span class="nav-number">3.2.</span> <span class="nav-text">2.2.2 对话式分块</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-3-%E8%AF%AD%E4%B9%89%E4%B8%8E%E4%B8%BB%E9%A2%98%E5%88%86%E5%9D%97"><span class="nav-number">4.</span> <span class="nav-text">2.3 语义与主题分块</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-1-%E8%AF%AD%E4%B9%89%E5%88%86%E5%9D%97"><span class="nav-number">4.1.</span> <span class="nav-text">2.3.1 语义分块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-3-2-%E5%9F%BA%E4%BA%8E%E4%B8%BB%E9%A2%98%E7%9A%84%E5%88%86%E5%9D%97"><span class="nav-number">4.2.</span> <span class="nav-text">2.3.2 基于主题的分块</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#2-4-%E9%AB%98%E7%BA%A7%E5%88%86%E5%9D%97%E7%AD%96%E7%95%A5"><span class="nav-number">5.</span> <span class="nav-text">2.4 高级分块策略</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-1-%E5%B0%8F-%E5%A4%A7%E5%88%86%E5%9D%97"><span class="nav-number">5.1.</span> <span class="nav-text">2.4.1 小-大分块</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#2-4-2-%E4%BB%A3%E7%90%86%E5%BC%8F%E5%88%86%E5%9D%97"><span class="nav-number">5.2.</span> <span class="nav-text">2.4.2 代理式分块</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#%E7%BB%93%E8%AE%BA%EF%BC%9A%E5%88%86%E5%9D%97%E6%98%AF%E5%AE%9E%E8%B7%B5%EF%BC%8C%E8%80%8C%E9%9D%9E%E7%90%86%E8%AE%BA"><span class="nav-number"></span> <span class="nav-text">结论：分块是实践，而非理论</span></a></div>
      </div>
      <!--/noindex-->

      <div class="site-overview-wrap sidebar-panel">
        <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
    <img class="site-author-image" itemprop="image" alt="longchao"
      src="/images/avatar.gif">
  <p class="site-author-name" itemprop="name">longchao</p>
  <div class="site-description" itemprop="description">A blog about life, technology, and everything in between.</div>
</div>
<div class="site-state-wrap motion-element">
  <nav class="site-state">
      <div class="site-state-item site-state-posts">
          <a href="/archives/">
        
          <span class="site-state-item-count">246</span>
          <span class="site-state-item-name">日志</span>
        </a>
      </div>
      <div class="site-state-item site-state-categories">
        <span class="site-state-item-count">76</span>
        <span class="site-state-item-name">分类</span>
      </div>
      <div class="site-state-item site-state-tags">
        <span class="site-state-item-count">623</span>
        <span class="site-state-item-name">标签</span>
      </div>
  </nav>
</div>
  <div class="links-of-author motion-element">
      <span class="links-of-author-item">
        <a href="https://github.com/longchao012" title="GitHub → https:&#x2F;&#x2F;github.com&#x2F;longchao012" rel="noopener" target="_blank"><i class="fa fa-fw fa-github"></i>GitHub</a>
      </span>
      <span class="links-of-author-item">
        <a href="mailto:longchao012@gmail.com" title="E-Mail → mailto:longchao012@gmail.com" rel="noopener" target="_blank"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
      </span>
      <span class="links-of-author-item">
        <a href="https://plus.google.com/longchao012" title="Google → https:&#x2F;&#x2F;plus.google.com&#x2F;longchao012" rel="noopener" target="_blank"><i class="fa fa-fw fa-google"></i>Google</a>
      </span>
  </div>
  <div class="cc-license motion-element" itemprop="license">
    <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/" class="cc-opacity" rel="noopener" target="_blank"><img src="/images/cc-by-nc-sa.svg" alt="Creative Commons"></a>
  </div>



      </div>
        <div class="back-to-top motion-element">
          <i class="fa fa-arrow-up"></i>
          <span>0%</span>
        </div>

    </div>
  </aside>
  <div id="sidebar-dimmer"></div>


      </div>
    </main>

    <footer class="footer">
      <div class="footer-inner">
        

        

<div class="copyright">
  
  &copy; 2022 – 
  <span itemprop="copyrightYear">2025</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">longchao</span>
</div>

        
<div class="busuanzi-count">
  <script async src="https://busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script>
    <span class="post-meta-item" id="busuanzi_container_site_uv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-user"></i>
      </span>
      <span class="site-uv" title="总访客量">
        <span id="busuanzi_value_site_uv"></span>
      </span>
    </span>
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item" id="busuanzi_container_site_pv" style="display: none;">
      <span class="post-meta-item-icon">
        <i class="fa fa-eye"></i>
      </span>
      <span class="site-pv" title="总访问量">
        <span id="busuanzi_value_site_pv"></span>
      </span>
    </span>
</div>








      </div>
    </footer>
  </div>

  
  <script src="/lib/anime.min.js"></script>
  <script src="/lib/velocity/velocity.min.js"></script>
  <script src="/lib/velocity/velocity.ui.min.js"></script>

<script src="/js/utils.js"></script>

<script src="/js/motion.js"></script>


<script src="/js/schemes/pisces.js"></script>


<script src="/js/next-boot.js"></script>




  




  
<script src="/js/local-search.js"></script>













  

  

</body>
</html>
